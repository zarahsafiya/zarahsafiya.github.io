---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Zarah Jamaluddin (ZSJ223)"
date: '5/2/2021'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(sandwich)
library(vegan)
library(lmtest)
library(plotROC)
library(rstatix)
library(glmnet)

class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}
```

## 0. Introduction

```{R}
vgsales <- read_csv("vgsales.csv")
```

*In this investigation, I imported the vgsales dataset which highlights video game sales from 2014 to 2016 for the regions North America, Europe, and Japan. Within this dataset, the variables I am exploring include Name, Platform, Year, Genre, NA_Sales, EU_Sales, JP_Sales, Other_Sales, and Global_Sales with there being 292 total observations. Within these variables, "Name" represents the title of the individual video games and "Platform" represents the console names such as different variations of PlayStation, Xbox, Wii, and Nintendo DS consoles. Further, "Year" represents the year of the video game title release and "Genre" represents the genre of corresponding game. Lastly, NA_Sales, EU_Sales, JP_Sales, Other_Sales, and Global_Sales represents the sales of each video game title in millions within North America, Europe, Japan, all other regions, and total global sales respectively.*

## 1. MANOVA/ANOVA Testing

### MANOVA Test
```{R}
man1 <- manova(cbind(NA_Sales, EU_Sales, JP_Sales, Other_Sales)~Genre, data=vgsales)
summary(man1)
```
*I performed a MANOVA test to determine if one of my variables were significant or not. From this test, it can be seen that there is in fact at least one variable that is significant since the returned p-value was found to be 9.011e-08, thus causing me to next perform univariate ANOVA tests.*

*As there are several MANOVA test assumptions, it is likely that, while most of the test assumptions have been met, some of them were not met within this investigation. For instance, while the Action and Role-Playing genres very clearly each had over 25 observations, the other genres may not have had as many observations. Further, data being analyzed likely did meet the random samples and independent observations assumptions and the homogeneity of within-group covariance matrices assumptions. Lastly, there does appear to be a linear relationship among the dependent variables, are no obvious extreme univariate or multivariate outliers, and the dependent variables do not seem to have multicollinearity. Consequently, most of the MANOVA assumptions are most likely to have been met during this test.*

### Univariate ANOVA Test
```{R}
summary.aov(man1)
```
*From the conducted univariate ANOVA tests, it can be seen that the mean differences across NA_Sales (p-value=1.029e-05), EU_Sales (p-value=2.051e-05), and Other_Sales (p-value=2.815e-05) are significant. However, the mean difference across JP_Sales was not found to be significant as it only had a p-value of 0.3523.*

### Post-hoc T-tests
```{R}
pairwise.t.test(vgsales$NA_Sales,vgsales$Genre, p.adj= "none")
pairwise.t.test(vgsales$EU_Sales,vgsales$Genre, p.adj = "none")
pairwise.t.test(vgsales$Other_Sales,vgsales$Genre, p.adj = "none")
```
*As NA_Sales, EU_Sales, and Other_Sales were found to be significant through the univariate ANOVA test, I performed pairwise t-tests to further see if the mean differences between each genre differed for each of the three regions.*

### Probability of Type I Error and Bonferroni Corrected Post-hoc T-Tests
```{R}
(1-(0.95^89))
(.05/89)
pairwise.t.test(vgsales$NA_Sales,vgsales$Genre, p.adj = "bonferroni")
pairwise.t.test(vgsales$EU_Sales,vgsales$Genre, p.adj = "bonferroni")
pairwise.t.test(vgsales$Other_Sales,vgsales$Genre, p.adj = "bonferroni")
```
*From the pairwise t-tests, the probability of a type I error was found to be 0.9895912, or 98.96% and the adjusted significance level was equal to 0.0005617978.*

*Using this, I then conducted the bonferroni corrected pairwise t-tests and found that for NA_Sales the mean differences between the genres Shooter and Action, Shooter and Misc, Shooter and Role-Playing, and Sports and Shooter were significant.*

*Then, for EU_Sales the mean differences between the genres Shooter and Action, Shooter and Fighting, Shooter and Role-Playing, Sports and Action, and Sports and Role-Playing were significant.*

*Lastly, for Other_Sales the mean differences between the genres Shooter and Action, Shooter and Fighting, Shooter and Role-Playing, and Sports and Role-Playing were significant.* 

*From these mean differences, it is interesting to note that across all three regions investigated, only Shooter and Sports video games displayed mean differences across other genres that were found to be significant. This could possibly be explained by these genres having more overall sales within each region in comparison to other genres.*

## 2. Randomization Testing

### Mean Difference
```{R}
new_vgsales <- vgsales %>% filter(Genre == "Sports" | Genre == "Shooter")

rand_dist <- vector()

for(i in 1:5000){
  new_vgsales1 <- data.frame(NA_Sales=sample(new_vgsales$NA_Sales),Genre=new_vgsales$Genre)
  rand_dist[i] <- mean(new_vgsales1[new_vgsales1$Genre=="Sports",]$NA_Sales)-mean(new_vgsales1[new_vgsales1$Genre=="Shooter",]$NA_Sales)
}
new_vgsales %>% group_by(Genre) %>% summarize(means=mean(NA_Sales)) %>% summarize('mean_diff' = diff(means))
mean(rand_dist > 0.6537104 | rand_dist < -0.6537104)
```

### Plot Visualization
```{R}
{hist(rand_dist,main="",ylab=""); abline(v = c(-0.6537104, 0.6537104),col="red")}
```
*From the pairwise t-tests conducted for NA_Sales vs. Genre, I noticed that there was a significant p-value associated with the mean difference between Sports and Shooter video games. As a result, I chose to investigate these results further and performed a mean difference randomization test on this specific subset of my data. During this randomization test, my null hypothesis stated that mean NA_Sales are the same for Sports vs. Shooter games while my alternative hypothesis stated that mean NA_Sales are different for Sports vs. Shooter games. Through this randomization test, it can be seen that the p-value for the model was found to be 0.0218, thus causing the mean difference in NA_Sales to be significant between the two genres. Then, by creating a plot visualizing the null distribution and the test statistic (mean difference), it can be seen that the majority of the data falls within the two extremes of the actual test statistic, thus causing the actual mean difference to be large enough to suggest that the association between NA_Sales and Sports games and NA_Sales and Shooter games is not due to chance. Further, in this sampling distribution it can be seen that the probability of getting a mean difference at least as big as 0.6537104 is less than 0.05. Thus, using this randomization test, the null hypothesis would be rejected and it can be concluded that mean NA_Sales are different for Sports vs. Shooter games.*

## 3. Linear Regression Modeling

### Linear Regression
```{R}
new_vgsales3 <- vgsales %>% mutate(new_year = (as.factor(Year)))
new_vgsales3$NA_Sales_c <- new_vgsales3$NA_Sales - mean(new_vgsales3$NA_Sales)
new_vgsales3$EU_Sales_c <- new_vgsales3$EU_Sales - mean(new_vgsales3$EU_Sales)
new_vgsales3$JP_Sales_c <- new_vgsales3$JP_Sales - mean(new_vgsales3$JP_Sales)
new_vgsales3$Other_Sales_c <- new_vgsales3$Other_Sales - mean(new_vgsales3$Other_Sales)
new_vgsales3$Global_Sales_c <- new_vgsales3$Global_Sales - mean(new_vgsales3$EU_Sales)

fit <- lm(NA_Sales_c ~  EU_Sales_c * Genre, data=new_vgsales3)
summary(fit)
```
*In this linear regression model, I observed the interaction between EU_Sales and Genre to predict mean NA_Sales as I wanted to see if there was any relationship between the two regions of video game sales when genre varied. From this model it can be seen that under control of the Action genre and at the mean value for EU_Sales, NA_Sales is -0.5050 million below the mean NA_Sales. Further, for every increase of 1 million in mean EU_Sales, mean NA_Sales increases by 0.69267 million when compared to the Action Genre conditions. Using this model it can also be seen that at any given genre and at the mean value for EU_Sales, the mean NA_Sales is the value of the coefficient estimate higher or lower compared to the Action controlled genre conditions. For instance, for the fighting genre and at a mean value for EU_Sales, the mean NA_Sales is 0.68767 higher as compared to the controlled Action genre conditions. Furthermore, the effect of mean EU_Sales on mean NA_Sales is higher or lower by the coefficient estimate under genre conditions as compared to the control condition. For instance, the effect of mean EU_Sales on mean NA_Sales is 1.67726 million higher under the Fighting genre condition as compared to the Action Genre control condition. In other words, for the Fighting genre, the slope of mean EU_Sales and mean NA_Sales is 0.68767 + 1.67726 = 2.36493 million. Lastly, it can be seen that the R^2 value indicates that 79.1% of the variability in mean NA_Sales can be explained by this model.*

### Linear Regression Plot
```{R}
new_vgsales3 %>% select(NA_Sales_c, EU_Sales_c, Genre) %>% na.omit %>% ggplot(aes(EU_Sales_c, NA_Sales_c, color=Genre)) + geom_point()+geom_smooth(method="lm")+ geom_vline(xintercept=mean(new_vgsales3$EU_Sales_c),na.rm=T,lty=2)
```

### Check Assumptions
```{R}
resids <- fit$residuals
fitvals <- fit$fitted.values
ggplot() + geom_point(aes(fitvals, resids)) + geom_hline(yintercept=0, color="red")
ks.test(resids, "pnorm", mean=0, sd(resids))
```
*From checking the assumptions graphically, it can be seen that this model fails the assumptions of normality as the One-sample Kolmogorov-Smirnov test shows the model having a p-value of 5.271e-09, thus causing me to reject the null hypothesis which states that the linear regression model is normally distributed. Further, this linear regression model also violates the assumption of homoskedasticity as the shape of the graph fans out. However, as there is no apparent pattern (such as curving) within this graph, the model does not violate linearity.*

### Linear Regression with Robust Standard Errors
```{R}
coeftest(fit, vcov = vcovHC(fit))
```
*From the linear regression model with robust standard errors via the coeftest(..., vcoc=vcocHC(...)), it is seen that the effects on mean NA_Sales for the the Role-Playing genre when at a mean value for EU_Sales is no longer significant. Further, while the effects on mean NA_Sales for the Shooter genre when at a mean value for EU_Sales is still significant, it is now slightly less significant that in the original linear regression model. Moreover, it can be seen that the after the robust SEs has been applied, the effect of mean EU_Sales on mean NA_Sales for the Racing and Role-Playing genres are no longer significant. Lastly, while the effect of mean EU_Sales on mean NA_Sales for the Shooter genre is still significant, it is now slightly less significant than in the original linear regression model.*

## 4. Linear Regression Modeling with Bootstrapped Standard Errors

```{R}
samp_distn <- replicate(5000, {
  boot_dat <- sample_frac(new_vgsales3, replace = T)
  fit2 <- lm(NA_Sales_c ~ EU_Sales_c * Genre, data = boot_dat)
  coef(fit2)
})

samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
```
*From the regression model computed with bootstrapped standard errors as compared to the original regression, the standard errors for the effects of EU_Sales_c, GenreFighting, GenreMisc, GenreRole-Playing, GenreShooter, and GenreSports increased and the standard errors for the interactions of EU_Sales_c:GenreFighting, EU_Sales_c:GenreMisc, EU_Sales_c:GenreRacing, EU_Sales_c:GenreRole-Playing, EU_Sales_c:GenreShooter, and EU_Sales_c:GenreSports increased. This means that the p-value using these SEs is higher when compared to the original SEs. The other effects and interactions decreased in SE values from the bootstrapped standard errors as compared to the original regression, thus meaning that the p-value for these SEs decreased.*

*Next, from the regression model computed with bootstrapped standard errors as compared to the regression model with robust SEs, the standard errors for the effects of GenreFighting and GenreSports increased and the standard errors for the interactions of EU_Sales_c:GenreFighting, EU_Sales_c:GenreShooter, and EU_Sales_c:GenreSports increased. This means that the p-value using these SEs is higher when compared to the original SEs. The other effects and interactions decreased in SE values from the bootstrapped standard errors as compared to the original regression, thus meaning that the p-value for these SEs decreased.*

## 5. Logistic Regression Modeling with Two Explanatory Variables

### Logistic Regression
```{R}
new_vgsales4 <- vgsales %>% mutate(y=ifelse(Platform=="PS4",1,0))
new_vgsales4_fit <- glm(y ~ NA_Sales + EU_Sales, data=new_vgsales4, family=binomial(link="logit"))
exp(coef(new_vgsales4_fit))
```
*By creating a logistic regression model, I was able to predict the odds of the video game platform being a PS4 from the explanatory variables of NA_Sales and EU_Sales. From this model, it can be seen that for every 1 million increase in NA_Sales while controlling for EU_Sales, the odds of the platform of the video game being PS4 is multiplied by the coefficient estimate of 0.2361657. It can also be seen that for every 1 million increase in EU_Sales while controlling for NA_Sales, the odds of the platform of video game being PS4 is multiplied by the coefficient estimate of 8.5875714. These coefficient estimates show that EU_Sales have a greater positive impact on the odds of the platform of the video game being PS4 as compares to NA_Sales.*

### Confusion Matrix and Accurary, Sensitivity, and Specificity
```{R}
probability <- predict(new_vgsales4_fit, type = "response")
class_diag(probability, new_vgsales4$y)
table(predict = as.numeric(probability > 0.5), truth = new_vgsales4$y) %>% 
    addmargins
```
*From the confusion matrix for the logistic regression, it is seen that the Accuracy for the model, otherwise known as the proportion of correctly classified cases is 0.6975089. Next, the Sensitivity of the model, which represents the proportion of non-PS4 platforms correctly classified is 0.3760684. Then, the Specificity of the model, also known as the proportion of PS4 platforms correctly classified is 0.9268293. Further, the Precision of the model, which represents the proportion of classified non-PS4 platforms that actually are non-PS4 platforms is 0.7857143. Lastly, the AUC of the model, which shows that the probability that a randomly selected video game on the PS4 platform has a higher predicted probability than a randomly selected video game on a non-PS4 platform, was found to be 0.7667292. Therefore, the AUC of the model is considered to be fair.*

### Density Plot
```{R}
new_vgsales4 <- new_vgsales4 %>% mutate(Platform=ifelse(y==1, "PS4", "non-PS4"))
new_vgsales4$logit <- predict(new_vgsales4_fit, type="link")
new_vgsales4 %>% mutate(Platform=as.factor(Platform)) %>% ggplot() + geom_density(aes(logit, fill=Platform), alpha=0.4) + theme(legend.position=c(0.85, 0.85)) + xlab("logit(log-odds)") + geom_vline(xintercept=0)
```

### ROC Plot and AUC
```{R}
plot <- ggplot(new_vgsales4) + geom_roc(aes(d=y, m=NA_Sales + EU_Sales), n.cuts=0)
plot
calc_auc(plot)
```
*From the generated ROC plot, the trade-off between sensitivity (true positive rate) and specificity (true negative rate, otherwise known as the false positive rate) can be visualized. Further, the AUC of the plot was found to be 0.6099385, thus causing the AUC to be considered to be poor. This means that it is hard to predict whether a video game was on the PS4 platform or not from just NA_Sales and EU_Sales.*

## 6. Logistic Regression Modeling with All Variables

### Logistic Regression and In-Sample Classification Diagnostics
```{R}
new_vgsales5 <- new_vgsales4 %>% mutate(new_year = (as.factor(Year)))
new_vgsales5 <- new_vgsales5 %>% select(y, JP_Sales, Other_Sales, new_year, Genre)
new_vgsales5_fit <- glm(y~ JP_Sales + Other_Sales + new_year + Genre, data=new_vgsales5, family=binomial(link="logit"))
probability2 <- predict(new_vgsales5_fit, type="response")
class_diag(probability2, new_vgsales5$y)
```
*From the confusion matrix for the logistic regression, it is seen that the Accuracy for the model, otherwise known as the proportion of correctly classified cases is 0.7508897. Next, the Sensitivity of the model, which represents the proportion of non-PS4 platforms correctly classified is 0.6239316. Then, the Specificity of the model, also known as the proportion of PS4 platforms correctly classified is 0.8414634. Further, the Precision of the model, which represents the proportion of classified non-PS4 platforms that actually are non-PS4 platforms is 0.7373737. Lastly, the AUC of the model, which shows that the probability that a randomly selected video game on the PS4 platform has a higher predicted probability than a randomly selected video game on a non-PS4 platform, was found to be 0.8227538. Therefore, the AUC of the model is considered to be fair.*

### 10-Fold CV and Average Out-of-Sample Classification Diagnostics
```{R}
set.seed(1234)
k=10

data <- new_vgsales5[sample(nrow(new_vgsales5)),]
folds <- cut(seq(1:nrow(new_vgsales5)),breaks=k, labels=F)

diags <- NULL
for(i in 1:k){
  train <- data[folds!=i,]
  test <- data[folds==i,]
  truth <- test$y
  fit <- glm(y~ JP_Sales + Other_Sales + new_year + Genre, data=train, family=binomial(link="logit"))
  probs <- predict(fit, newdata=test, type="response")
  diags <- rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean)
```
*From the confusion matrix for the logistic regression, it is seen that the Accuracy for the model is 0.6903941	which is lower than the Accuracy of the previous model which was found to be 0.7508897. Next, the Sensitivity of the model is 0.5247804 which is lower than the Sensitivity of the previous model which was found to be 0.6239316. Then, the Specificity of the model is 0.8149155 which is lower than the Specificity of the previous model which was found to be 0.8414634. Further, the Precision of the model is 0.6522872 which is lower than the Precision of the previous model which was found to be 0.7373737. Lastly, the AUC of the model is 0.7908715 which is lower than the AUC of the previous model which was found to be 0.8227538. Therefore, the AUC of the current model is considered to be fair which is worse than the AUC of the previous model which was considered to be good.*

### LASSO Model
```{R}
y <- as.matrix(new_vgsales5$y)
x <- model.matrix(y~., data=new_vgsales5)[,-1]

cv <- cv.glmnet(x,y,family="binomial")
lasso <- glmnet(x,y,family="binomial", lambda=cv$lambda.1se)
coef(lasso)
```
*After performing a LASSO on the same model and variables as the 10-fold CV it can be seen that the JP_Sales, Other_Sales, new_year2015, new_year2016, GenreMisc, and GenreRacing variables were retained. These variables thus had the accuracy that was near that of the best (lambda.1se) and were found to be the best predictor variables for if a video game was on the PS4 platform.*

### 10-Fold CV with Lasso Variables
```{R}
set.seed(1234)
k=10
new_vgsales6 <- new_vgsales5 %>% mutate(new_year2015=ifelse(new_vgsales5$new_year=="2015",1,0),new_year2016=ifelse(new_vgsales5$new_year=="2016",1,0))
new_vgsales6 <- new_vgsales6 %>% mutate(GenreMisc=ifelse(new_vgsales6$Genre=="Misc",1,0),GenreRacing=ifelse(new_vgsales6$Genre=="Racing",1,0))
data <- new_vgsales6[sample(nrow(new_vgsales6)),]
folds <- cut(seq(1:nrow(new_vgsales6)),breaks=k, labels=F)

diags <- NULL
for(i in 1:k){
  train <- data[folds!=i,]
  test <- data[folds==i,]
  truth <- test$y
  fit <- glm(y~ JP_Sales + Other_Sales + new_year2015 + new_year2016 + GenreMisc + GenreRacing, data=train, family=binomial(link="logit"))
  probs <- predict(fit, newdata=test, type="response")
  diags <- rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean)
```
*After performing the 10-fold CV using only the JP_Sales, Other_Sales, new_year2015, new_year2016, GenreMisc, and GenreRacing variables that were selected from the lasso model it can be seen that the AUC of this model was found to be 0.7875701, thus causing this model to be considered to be fair. As the AUC of the 10-fold CV model using all variables was 0.7908715, this causes the AUC of the current model to be lower than the previous model. However, as these AUC values were very close to one another and both are considered to be fair, this likely means that the original 10-fold CV model was not over-fitting too much.*

...





